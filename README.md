# An Empirical Study of Overfitting and Generalization in Neural Networks

## Overview
Work in progress.

## Motivation
Neural networks often achieve near-perfect training accuracy while generalizing poorly.
This project aims to empirically study how model capacity and data size influence
generalization behavior under controlled settings.

## Experimental Setup
Work in progress.

## Results
Preliminary experiments indicate that increasing network depth improves training performance but can exacerbate overfitting under fixed data regimes.
Reducing the amount of training data significantly increases the generalization gap.
With limited data, models achieve high training accuracy but exhibit degraded and unstable validation performance, highlighting the role of data availability in controlling overfitting.
Applying dropout regularization reduces training accuracy but improves validation stability, indicating a trade-off between model capacity and generalization that aligns with classical overfitting theory.


## Limitations
Work in progress.

