# An Empirical Study of Overfitting and Generalization in Neural Networks

## Overview
Work in progress.

## Motivation
Neural networks often achieve near-perfect training accuracy while generalizing poorly.
This project aims to empirically study how model capacity and data size influence
generalization behavior under controlled settings.

## Experimental Setup
Work in progress.

## Results
Preliminary experiments indicate that increasing network depth improves training performance but can exacerbate overfitting under fixed data regimes.


## Limitations
Work in progress.

